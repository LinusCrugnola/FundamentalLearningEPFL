{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"GteYUTHvkZtc"},"source":["# EE-411 Fundamentals of inference and learning, EPFL \n","## Exercise Session 5: Regularized least-squares and gradient descent methods\n","### 7 questions, 1 point each. Maximum score: **6**!\n","### You can skip one question and still get the full score.\n","\n","... In progress ...\n","\n","**What you will learn today:** In this fifth notebook, you will have your first hands-on application on parametric methods in machine learning. We shall see how to use python to solve least-squared problems, and how to implement gradient descent for optimizing different functions. You will also gain intuition about various gradient descent methods by visualizing and applying these methods to some simple two-dimensional surfaces. Methods studied include ordinary gradient descent, gradient descent with momentum and NAG."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"FoIL_ex4_solved.ipynb","provenance":[]},"interpreter":{"hash":"71c7e7b62c8b549c17c4ebe2a10e4a9947302b4a8b96addff24585ab9f2f668b"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
